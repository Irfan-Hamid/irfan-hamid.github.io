<!-- Light Navigation Bar -->
<nav style="position: sticky; top: 0; background-color: #ffffff; padding: 12px 20px; font-family: sans-serif; font-size: 16px; z-index: 999; border-bottom: 1px solid #ccc;">
  <a href="#education" style="margin-right: 20px; text-decoration: none; font-weight: bold; color: #333;">Education</a>
  <a href="#work-experience" style="margin-right: 20px; text-decoration: none; font-weight: bold; color: #333;">Experience</a>
  <a href="#projects" style="margin-right: 20px; text-decoration: none; font-weight: bold; color: #333;">Projects</a>
  <a href="#skills" style="margin-right: 20px; text-decoration: none; font-weight: bold; color: #333;">Skills</a>
  <a href="/assets/resume/Irfan_Resume.pdf" download style="text-decoration: none; font-weight: bold; color: #333;">Download Resume</a>
</nav>

# Hi, I'm Irfan Hamid

*Exploring the frontiers of Artificial Intelligence, driven by curiosity and precision. I thrive on turning complex theories into powerful real-world applications â€” from satellite-based tree classification to novel Transformer architectures and model robustness research. I bring a hybrid background across AI, deep learning, and scalable data engineering solutions.*

ðŸ“« **irfanhamid19@gmail.com**  
ðŸ“± **+91 9789596664** | **+44 7471069088**  
[LinkedIn](https://www.linkedin.com/in/irfan-hamid/) â€¢ [GitHub](https://github.com/Irfan-Hamid)

---

## <span id="education" style="font-size: 28px; font-weight: bold; color: #000;">Education</span>

**The University of Edinburgh** *(MSc in Artificial Intelligence, Sep 2023 â€“ Nov 2024)*  
**Vellore Institute of Technology (VIT), India** *(BTech in Electrical and Electronics Engineering, Jun 2017 â€“ Jun 2021)*

---

## <span id="work-experience" style="font-size: 28px; font-weight: bold; color: #000;">Work Experience</span>

**Forest Research (The research agency of the Forestry Commission, UK government), Northern Research Station**  
**Student Researcher**  
_March 2024 â€“ August 2024_  
â€¢ Conducted an industry-partnered machine learning research with Forest Research for my MSc dissertation, focusing on the classification of tree species in the Forest of Dean using high-resolution multispectral satellite imagery from Planet Labsâ€™ SuperDove 8 satellites  
â€¢ Implemented and trained deep learning models, including ResNet-34, DenseNet-40 and Vision Transformers (ViT) to perform species classification. Utilized QGIS for geospatial preprocessing, spatial analysis, and visualization of labelled tree data  
â€¢ Performed a comparative evaluation of the models and analyzed classification accuracy across various tree species. Additionally, examined species spectral curves to explain predictions, contributing to precision forestry and remote sensing applications

**Wipro Limited, Chennai, India**  
**SAP BW Consultant**  
_July 2021 â€“ June 2023_  
â€¢ Designed and optimized SAP BW process chains for Nomad Foods Europe Limited, improving automation and data integration  
â€¢ Developed customized SAP BW queries aligned with business KPIs for accurate, actionable reporting  
â€¢ Implemented SAP BW/4HANA data provisioning and ETL processes, enhancing BI report performance and operational decision-making

---

## <span id="projects" style="font-size: 28px; font-weight: bold; color: #000;">Projects</span>

### Non-Self-Referential Attention in Transformers  
[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-black?logo=github)](https://github.com/Irfan-Hamid/Rethinking-Attention-for-Transformers)

â€¢ Explored modifications to Transformer architecture and developed a method called Non-Self-Referential Attention  
â€¢ Driven by the observation that self-attention values (main diagonal of the attention matrix) were often disproportionately high yet minimally informative, this method attenuated those values by a tunable factor to diversify attention distributions and improve performance on tasks like machine translation  
â€¢ Applied this approach to the 'en-pt' translation subset of the opus_books dataset, achieving a 2.12% BLEU score improvement

---

### Retrieval-Augmented Generation (RAG) Pipeline for Textbook Search  
[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-black?logo=github)](https://github.com/Irfan-Hamid/LLM_RAG_IMPLEMENTATION)

â€¢ Extracted and preprocessed text from PDF textbooks, formatted it into chunks and converted them into numerical embeddings  
â€¢ Designed a vector-based retrieval system to identify and extract relevant text chunks based on user queries  
â€¢ Generated context-aware prompts using retrieved passages and utilized LLM (Google/GEMMA-7B-it) to produce accurate, context-driven responses to queries derived from textbook content

---

### Multi-Label Learning from Single Positive Labels  
[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-black?logo=github)](https://github.com/Irfan-Hamid/Multi-Label-Learning-from-Single-Positive-Labels)

â€¢ This project explores the challenge of multi-label classification in settings where each training example is annotated with only a single positive label, despite the presence of multiple applicable labels. In real-world scenarios, especially when the number of potential labels is large, it becomes impractical for human annotators to exhaustively list all relevant labels for each instance. This results in sparsely labeled data that is difficult to learn from using conventional techniques.  
â€¢ A practical example of this problem arises in species distribution modeling (SDM), where the goal is to predict the presence or absence of species across geographic regions based on limited field observations. In such datasets, only the locations where a species has been observed are recorded, and absence information is typically unavailable, making the task more complex and imbalanced.  
â€¢ A neural network was trained to perform accurate multi-label inference at test time despite being exposed to only a single positive label per instance during training.  
â€¢ Introduced a custom loss function called **UPL (Up-weighting Positive Label)**, which increases the contribution of observed labels while handling ambiguity in the unobserved ones.  
â€¢ The UPL loss resulted in a **72% improvement in performance** over standard binary cross-entropy loss across key evaluation metrics.

---

### Evaluating the Robustness of Classical ML vs Deep Learning for Image Classification  
[![View on GitHub](https://img.shields.io/badge/View_on-GitHub-black?logo=github)](https://github.com/Irfan-Hamid/Robustness-Comparison-Classical-machine-learning-vs.-Deep-Learning-in-Image-Classification)

â€¢ Investigated the robustness of classical machine learning models compared to deep learning architectures when exposed to real-world variations in image quality  
â€¢ Random Forest and Support Vector Machine (SVM) were used as classical baselines, while AlexNet, a convolutional neural network, represented the deep learning approach  
â€¢ All models were trained on the clean version of the **Sports Balls Multiclass Image Classification** dataset from Kaggle, containing over 9,000 images across 15 sports ball categories  
â€¢ Robustness testing involved introducing controlled perturbations, including Gaussian noise, blurring, contrast and brightness shifts, occlusion, and salt-and-pepper noise  
â€¢ Results showed that classical models deteriorated significantly under noisy conditions, while AlexNet maintained a higher level of performance, demonstrating stronger generalization to distorted inputs

---

## <span id="skills" style="font-size: 28px; font-weight: bold; color: #000;">Skills</span>

â€¢ **Programming Languages & Tools:** Python, SQL, Git, Docker, AWS, Kubernetes  
â€¢ **Libraries & Frameworks:** PyTorch, NumPy, Pandas, scikit-learn, OpenCV  
â€¢ **NLP & LLMs:** Transformers (Hugging Face), spaCy, NLTK, LlamaIndex  
â€¢ **Machine Learning:** Deep Learning, Bayesian Inference, VAEs, Approximate Inference  
â€¢ **Domains:** Computer Vision, NLP, Large Language Models (LLMs), LLM Fine-Tuning (LoRA), Retrieval-Augmented Generation (RAG), LLM Compression  
â€¢ **MLOps:** GitHub Actions, DVC, MLflow


